Field                                                                                                  |  Response
:------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------
Intended Task/Domain:                                                                                  |  Accessibility enablement in healthcare and enterprise settings: real-time conversion of documents and instructions into ASL (via avatars), simplified text, closed captioning, and auditory formats.
Model Type:                                                                                            |  Multimodal generative AI system integrating NLP (text simplification), TTS (speech output), and avatar-based ASL translation. Built with NVIDIA NeMo, Riva, and TAO fine-tuned models.
Intended Users:                                                                                        |  Patients, caregivers, and staff with accessibility needs (Deaf/hard-of-hearing, blind/visually impaired, neurodivergent populations); healthcare providers seeking compliant, accessible communication tools, schools, government, etc.
Output:                                                                                                |  ASL avatar video, simplified text (6th grade level), closed captions, and synthesized audio.
(For GPAI Models): Tools used to evaluate datasets to identify synthetic data and ensure data authenticity | NVIDIA NeMo Data Curator and Guardrails, supplemented with third-party dataset validation tools (e.g., DataPerf, Synthetic Data Vault checks).
Describe how the model works:                                                                          |  Input text (e.g., discharge instructions) is processed through NVIDIA NeMo NLP pipelines for simplification and captioning, then routed to Riva TTS for speech output. Parallel ASL avatar generation is fine-tuned via TAO Toolkit with interpreter-validated training data. Outputs are synchronized to ensure timing consistency across modalities.
Name the adversely impacted groups this has been tested to deliver comparable outcomes regardless of:  |  Deaf and hard-of-hearing users, blind and visually impaired users, neurodivergent users, patients with limited literacy, and non-native English speakers.
Technical Limitations and Mitigation:                                                                  |  • ASL avatars may underperform on rare/technical terminology → mitigated with interpreter-verified phrase banks. • Simplification may over-reduce nuance → mitigated with dual outputs (simplified + full text). • Speech synthesis accent bias possible → mitigated with diverse voice datasets and NVIDIA Riva tuning.
Verified to have met prescribed [Insert Company Name Here] quality standards:                          |  Yes — validated against internal accessibility QA framework, HIPAA-aligned data handling, and NVIDIA partner evaluation protocols.
Performance Metrics:                                                                                   |  • Word Error Rate (WER) < 10% across groups. • ASL translation accuracy ≥ 85% vs. certified interpreters. • Simplified text readability target = 6th grade ± 1 grade. • Latency under 300ms for multimodal output generation
Potential Known Risks:                                                                                 |  Misinterpretation of critical medical content if simplification or translation fails. Risk mitigated by human-in-the-loop review for sensitive use cases (e.g., consent forms, discharge instructions).
Terms of Use/Licensing:                                                                                |  Licensed under Nclusive Scan’s enterprise subscription model. Incorporates NVIDIA NeMo/Riva/TAO frameworks under their respective licenses; third-party data subject to original terms.
 
